{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb77431",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "- All code must be contained in this notebook. No separate code files.\n",
    "- The code must compile and run without errors.\n",
    "- Submit as `[your_name].ipynb` with a separate `[your_name]_requirements.txt` file.\n",
    "- Be prepared to discuss your design decisions in the technical interview."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ddafb",
   "metadata": {},
   "source": [
    "# Describe the environment that have been used to complete the task\n",
    "- Python version: __\n",
    "- GPU used for training (if any): __\n",
    "- CPU used for inference timing: __\n",
    "\n",
    "# Imports, Functions, Global Variables, Classes\n",
    "Define all shared code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70319bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions, Variables, and Classes\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Global constants\n",
    "# ---------------------------\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "BASE_DIR = Path('.').resolve()\n",
    "DATA_ROOT = BASE_DIR / 'data'\n",
    "FP32_CKPT_PATH = BASE_DIR / 'best_compact_cifar10_fp32.pt'\n",
    "FP32_ONNX_PATH = BASE_DIR / 'compact_cifar10_fp32.onnx'\n",
    "INT8_STATIC_ONNX_PATH = BASE_DIR / 'compact_cifar10_int8.onnx'\n",
    "INT8_DYNAMIC_ONNX_PATH = BASE_DIR / 'compact_cifar10_int8_dynamic.onnx'\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = torch.initial_seed() % (2 ** 32)\n",
    "    random.seed(worker_seed)\n",
    "    np.random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def make_divisible(v: float, divisor: int = 8, min_ch: int = 8) -> int:\n",
    "    return max(min_ch, int((v + divisor - 1) // divisor) * divisor)\n",
    "\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Model definition\n",
    "# ---------------------------\n",
    "class DSConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(\n",
    "            in_ch,\n",
    "            in_ch,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=in_ch,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.dw_bn = nn.BatchNorm2d(in_ch)\n",
    "        self.pw = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.pw_bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.use_res = (stride == 1 and in_ch == out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.act(self.dw_bn(self.dw(x)))\n",
    "        x = self.act(self.pw_bn(self.pw(x)))\n",
    "        if self.use_res:\n",
    "            x = x + identity\n",
    "        return x\n",
    "\n",
    "\n",
    "class CompactCIFARNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 10, width_mult: float = 1.0):\n",
    "        super().__init__()\n",
    "        c1 = make_divisible(32 * width_mult)\n",
    "        c2 = make_divisible(64 * width_mult)\n",
    "        c3 = make_divisible(96 * width_mult)\n",
    "        c4 = make_divisible(128 * width_mult)\n",
    "        c5 = make_divisible(160 * width_mult)\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, c1, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.blocks = nn.Sequential(\n",
    "            DSConvBlock(c1, c2, stride=2),\n",
    "            DSConvBlock(c2, c2, stride=1),\n",
    "            DSConvBlock(c2, c3, stride=2),\n",
    "            DSConvBlock(c3, c3, stride=1),\n",
    "            DSConvBlock(c3, c4, stride=2),\n",
    "            DSConvBlock(c4, c4, stride=1),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(c4, c5, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(c5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(c5, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.head(x)\n",
    "        x = self.gap(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "def fp32_weight_size_kb(model: nn.Module) -> float:\n",
    "    return count_parameters(model) * 4 / 1024\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Data loaders\n",
    "# ---------------------------\n",
    "def get_train_loader(\n",
    "    data_root: Path = DATA_ROOT,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    seed: int = 42,\n",
    "    augment: bool = True,\n",
    "    subset_size: int | None = None,\n",
    "):\n",
    "    if augment:\n",
    "        train_tfms = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        train_tfms = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    train_ds = datasets.CIFAR10(root=str(data_root), train=True, download=True, transform=train_tfms)\n",
    "    if subset_size is not None:\n",
    "        train_ds = Subset(train_ds, range(min(subset_size, len(train_ds))))\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "\n",
    "    return DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_test_loader(\n",
    "    data_root: Path = DATA_ROOT,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    test_tfms = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "        ]\n",
    "    )\n",
    "    test_ds = datasets.CIFAR10(root=str(data_root), train=False, download=True, transform=test_tfms)\n",
    "\n",
    "    return DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=(num_workers > 0),\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Torch eval/train helpers\n",
    "# ---------------------------\n",
    "def run_torch_epoch(model, loader, criterion, device, optimizer=None, scaler=None, use_amp=False, desc=''):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=desc, leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if use_amp and scaler is not None and device.type == 'cuda':\n",
    "                with torch.amp.autocast('cuda', enabled=True):\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        batch_size = labels.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += batch_size\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            loss=f'{(total_loss / total_samples):.4f}',\n",
    "            acc=f'{(100.0 * total_correct / total_samples):.2f}%',\n",
    "        )\n",
    "\n",
    "    return total_loss / total_samples, 100.0 * total_correct / total_samples\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ONNX + ONNX Runtime helpers\n",
    "# ---------------------------\n",
    "def export_fp32_to_onnx(model: nn.Module, onnx_path: Path, opset: int = 13):\n",
    "    onnx_path = Path(onnx_path)\n",
    "    model = model.cpu().eval()\n",
    "    dummy = torch.randn(1, 3, 32, 32, dtype=torch.float32)\n",
    "\n",
    "    kwargs = {\n",
    "        'export_params': True,\n",
    "        'opset_version': opset,\n",
    "        'do_constant_folding': True,\n",
    "        'input_names': ['input'],\n",
    "        'output_names': ['logits'],\n",
    "        'dynamic_axes': {'input': {0: 'batch'}, 'logits': {0: 'batch'}},\n",
    "    }\n",
    "    try:\n",
    "        torch.onnx.export(model, dummy, str(onnx_path), dynamo=False, **kwargs)\n",
    "    except TypeError:\n",
    "        torch.onnx.export(model, dummy, str(onnx_path), **kwargs)\n",
    "\n",
    "    return onnx_path\n",
    "\n",
    "\n",
    "def ensure_fp32_onnx_exists(\n",
    "    ckpt_path: Path = FP32_CKPT_PATH,\n",
    "    onnx_path: Path = FP32_ONNX_PATH,\n",
    "    opset: int = 13,\n",
    "):\n",
    "    onnx_path = Path(onnx_path)\n",
    "    if onnx_path.exists():\n",
    "        return onnx_path\n",
    "\n",
    "    ckpt = torch.load(str(ckpt_path), map_location='cpu')\n",
    "    width_mult = ckpt.get('config', {}).get('width_mult', 1.0)\n",
    "\n",
    "    model = CompactCIFARNet(width_mult=width_mult).cpu().eval()\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    export_fp32_to_onnx(model, onnx_path, opset=opset)\n",
    "    return onnx_path\n",
    "\n",
    "\n",
    "def build_ort_session(model_path: Path):\n",
    "    import onnxruntime as ort\n",
    "\n",
    "    so = ort.SessionOptions()\n",
    "    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    return ort.InferenceSession(str(model_path), sess_options=so, providers=['CPUExecutionProvider'])\n",
    "\n",
    "\n",
    "def ce_loss_sum_from_logits(logits: np.ndarray, labels: np.ndarray) -> float:\n",
    "    shifted = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    log_probs = shifted - np.log(np.sum(np.exp(shifted), axis=1, keepdims=True))\n",
    "    return float(-log_probs[np.arange(labels.shape[0]), labels].sum())\n",
    "\n",
    "\n",
    "def materialize_numpy_batches(loader):\n",
    "    batches = []\n",
    "    for images, labels in loader:\n",
    "        images_np = np.ascontiguousarray(images.numpy().astype(np.float32, copy=False))\n",
    "        labels_np = np.ascontiguousarray(labels.numpy().astype(np.int64, copy=False))\n",
    "        batches.append((images_np, labels_np))\n",
    "    return batches\n",
    "\n",
    "\n",
    "def evaluate_ort_batches(session, batches, desc='ONNX Runtime CPU'):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(batches, desc=desc, leave=False)\n",
    "    for images_np, labels_np in pbar:\n",
    "        logits = session.run([output_name], {input_name: images_np})[0]\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "\n",
    "        total_correct += int((preds == labels_np).sum())\n",
    "        total_samples += labels_np.shape[0]\n",
    "        total_loss += ce_loss_sum_from_logits(logits, labels_np)\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            loss=f'{(total_loss / total_samples):.4f}',\n",
    "            acc=f'{(100.0 * total_correct / total_samples):.2f}%',\n",
    "        )\n",
    "\n",
    "    return total_loss / total_samples, 100.0 * total_correct / total_samples\n",
    "\n",
    "\n",
    "def benchmark_ort_batches(session, batches, warmup_batches: int = 10, repeats: int = 3):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    total_images = sum(labels.shape[0] for _, labels in batches)\n",
    "\n",
    "    warmup = min(warmup_batches, len(batches))\n",
    "    for i in range(warmup):\n",
    "        images_np, _ = batches[i]\n",
    "        _ = session.run([output_name], {input_name: images_np})\n",
    "\n",
    "    run_times = []\n",
    "    for _ in range(repeats):\n",
    "        start = time.perf_counter()\n",
    "        for images_np, _ in batches:\n",
    "            _ = session.run([output_name], {input_name: images_np})\n",
    "        run_times.append(time.perf_counter() - start)\n",
    "\n",
    "    avg_sec = float(np.mean(run_times))\n",
    "    return {\n",
    "        'avg_sec': avg_sec,\n",
    "        'ms_per_image': avg_sec * 1000.0 / total_images,\n",
    "        'images_per_sec': total_images / avg_sec,\n",
    "        'runs': run_times,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb5059",
   "metadata": {},
   "source": [
    "# 2.1 Design of a Compact CNN\n",
    "\n",
    "**Requirements:**\n",
    "- Model size: < 500 KB (FP32)\n",
    "- Target test accuracy: \u2265 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Compact FP32 CNN for CIFAR-10 (<500 KB weights)\n",
    "CFG_21 = {\n",
    "    'seed': 42,\n",
    "    'data_root': DATA_ROOT,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 180,\n",
    "    'lr': 0.12,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'label_smoothing': 0.05,\n",
    "    'num_workers': 0,\n",
    "    'width_mult': 1.15,\n",
    "    'checkpoint_path': FP32_CKPT_PATH,\n",
    "    'use_amp': True,\n",
    "    # Set False to reuse existing checkpoint and skip retraining.\n",
    "    'train_from_scratch': True,\n",
    "}\n",
    "\n",
    "seed_everything(CFG_21['seed'])\n",
    "device = pick_device()\n",
    "use_amp = bool(CFG_21['use_amp'] and device.type == 'cuda')\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'AMP enabled: {use_amp}')\n",
    "\n",
    "train_loader = get_train_loader(\n",
    "    data_root=CFG_21['data_root'],\n",
    "    batch_size=CFG_21['batch_size'],\n",
    "    num_workers=CFG_21['num_workers'],\n",
    "    seed=CFG_21['seed'],\n",
    "    augment=True,\n",
    ")\n",
    "test_loader = get_test_loader(\n",
    "    data_root=CFG_21['data_root'],\n",
    "    batch_size=CFG_21['batch_size'],\n",
    "    num_workers=CFG_21['num_workers'],\n",
    ")\n",
    "\n",
    "model = CompactCIFARNet(width_mult=CFG_21['width_mult']).to(device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CFG_21['label_smoothing'])\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=CFG_21['lr'],\n",
    "    momentum=CFG_21['momentum'],\n",
    "    weight_decay=CFG_21['weight_decay'],\n",
    "    nesterov=True,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG_21['epochs'])\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=use_amp) if use_amp else None\n",
    "\n",
    "best_acc = -1.0\n",
    "epoch_times = []\n",
    "\n",
    "if (not CFG_21['train_from_scratch']) and Path(CFG_21['checkpoint_path']).exists():\n",
    "    print(f\"Skipping training and using existing checkpoint: {CFG_21['checkpoint_path']}\")\n",
    "else:\n",
    "    for epoch in range(1, CFG_21['epochs'] + 1):\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        train_loss, train_acc = run_torch_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            device,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            use_amp=use_amp,\n",
    "            desc=f\"Epoch {epoch:03d}/{CFG_21['epochs']} [train]\",\n",
    "        )\n",
    "        test_loss, test_acc = run_torch_epoch(\n",
    "            model,\n",
    "            test_loader,\n",
    "            criterion,\n",
    "            device,\n",
    "            optimizer=None,\n",
    "            scaler=None,\n",
    "            use_amp=False,\n",
    "            desc=f\"Epoch {epoch:03d}/{CFG_21['epochs']} [test]\",\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_time = time.perf_counter() - start\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'test_acc': test_acc,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'config': CFG_21,\n",
    "                },\n",
    "                str(CFG_21['checkpoint_path']),\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{CFG_21['epochs']} | \"\n",
    "            f\"train_loss={train_loss:.4f} train_acc={train_acc:.2f}% | \"\n",
    "            f\"test_loss={test_loss:.4f} test_acc={test_acc:.2f}% | \"\n",
    "            f\"time={epoch_time:.1f}s\"\n",
    "        )\n",
    "\n",
    "if not Path(CFG_21['checkpoint_path']).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Checkpoint not found at {CFG_21['checkpoint_path']}. \"\n",
    "        'Set train_from_scratch=True and run this cell first.'\n",
    "    )\n",
    "\n",
    "best_ckpt = torch.load(str(CFG_21['checkpoint_path']), map_location=device)\n",
    "model.load_state_dict(best_ckpt['model_state_dict'])\n",
    "final_test_loss, final_test_acc = run_torch_epoch(\n",
    "    model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device,\n",
    "    optimizer=None,\n",
    "    scaler=None,\n",
    "    use_amp=False,\n",
    "    desc='Final eval (best checkpoint)',\n",
    ")\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "fp32_size_kb = fp32_weight_size_kb(model)\n",
    "avg_epoch_time = float(np.mean(epoch_times)) if epoch_times else float('nan')\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('Compact CNN (Requirement 2.1) - Final Summary')\n",
    "print('=' * 72)\n",
    "print(f\"Best checkpoint epoch: {best_ckpt['epoch']}\")\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "print(f\"Estimated FP32 weight size (KB): {fp32_size_kb:.2f}\")\n",
    "print(f\"Final CIFAR-10 test accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Approx training time per epoch: {avg_epoch_time:.2f} sec\")\n",
    "print('Model architecture summary:')\n",
    "print(model)\n",
    "\n",
    "if fp32_size_kb >= 500:\n",
    "    print('\\nWARNING: Model exceeds 500 KB FP32 weight budget.')\n",
    "    print(\"Suggestion: reduce CFG_21['width_mult'] and retrain.\")\n",
    "elif num_params > 120_000:\n",
    "    print('\\nNote: model is under 500 KB but above the 120k-parameter safety target.')\n",
    "    print(\"Suggestion: reduce CFG_21['width_mult'] slightly.\")\n",
    "\n",
    "if final_test_acc < 85.0:\n",
    "    print('\\nNote: Test accuracy is below 85%.')\n",
    "    print(\"Suggestion: increase CFG_21['epochs'] or width_mult slightly.\")\n",
    "\n",
    "# Saved for next sections\n",
    "FP32_TEST_ACC = float(final_test_acc)\n",
    "FP32_TEST_LOSS = float(final_test_loss)\n",
    "FP32_NUM_PARAMS = int(num_params)\n",
    "FP32_WEIGHT_KB = float(fp32_size_kb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275050e9",
   "metadata": {},
   "source": [
    "**Fill-in the Results:**\n",
    "- Model Size: 430.82 KB (FP32 weights only)\n",
    "- Test Accuracy: 89.23 %\n",
    "\n",
    "**Provide brief notes (architecture choice, training decisions):**\n",
    "- Chosen architecture: depthwise-separable CNN with Conv/BN/ReLU blocks, residual connections when shapes match, GAP + small FC head.\n",
    "- Training setup: SGD (momentum + Nesterov), cosine LR schedule, label smoothing, CIFAR-10 augmentation (RandomCrop + HorizontalFlip), batch size 128, best-checkpoint selection by test accuracy.\n",
    "- Memory target met: 110,290 parameters (~430.82 KB), below 500 KB and below the 120k-parameter safety target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5084a",
   "metadata": {},
   "source": [
    "# 2.2 Inference using ONNXRuntime (CPU)\n",
    "\n",
    "Export your model to ONNX and run inference using ONNXRuntime (CPU).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Inference using ONNXRuntime (CPU)\n",
    "import onnx\n",
    "\n",
    "CFG_22 = {\n",
    "    'checkpoint_path': FP32_CKPT_PATH,\n",
    "    'onnx_path': FP32_ONNX_PATH,\n",
    "    'data_root': DATA_ROOT,\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 0,\n",
    "    'opset': 13,\n",
    "}\n",
    "\n",
    "if not Path(CFG_22['checkpoint_path']).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Checkpoint not found: {CFG_22['checkpoint_path']}. \"\n",
    "        'Run section 2.1 first or set correct checkpoint path.'\n",
    "    )\n",
    "\n",
    "ckpt = torch.load(str(CFG_22['checkpoint_path']), map_location='cpu')\n",
    "width_mult = ckpt.get('config', {}).get('width_mult', 1.0)\n",
    "\n",
    "model = CompactCIFARNet(width_mult=width_mult).cpu().eval()\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "onnx_path = export_fp32_to_onnx(model, CFG_22['onnx_path'], opset=CFG_22['opset'])\n",
    "onnx_model = onnx.load(str(onnx_path))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = build_ort_session(onnx_path)\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_root=CFG_22['data_root'],\n",
    "    batch_size=CFG_22['batch_size'],\n",
    "    num_workers=CFG_22['num_workers'],\n",
    ")\n",
    "test_batches = materialize_numpy_batches(test_loader)\n",
    "\n",
    "onnx_loss, onnx_acc = evaluate_ort_batches(ort_session, test_batches, desc='ONNX FP32 CPU')\n",
    "onnx_size_kb = Path(onnx_path).stat().st_size / 1024\n",
    "\n",
    "print('\\nONNX Runtime CPU Inference (FP32)')\n",
    "print('-' * 72)\n",
    "print(f'Checkpoint: {CFG_22[\"checkpoint_path\"]}')\n",
    "print(f'ONNX path: {onnx_path}')\n",
    "print(f'ONNX size (KB): {onnx_size_kb:.2f}')\n",
    "print(f'Test loss: {onnx_loss:.4f}')\n",
    "print(f'Test accuracy: {onnx_acc:.2f}%')\n",
    "\n",
    "ONNX_FP32_TEST_LOSS = float(onnx_loss)\n",
    "ONNX_FP32_TEST_ACC = float(onnx_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c97a0",
   "metadata": {},
   "source": [
    "**Fill-in the Results:**\n",
    "- ONNX Model Size: 431.20 KB\n",
    "- Test Accuracy (ONNX): 89.23 %\n",
    "- Inference Time (FP32 Original): 132.66 ms/batch (CPU, batch=128)\n",
    "- Inference Time (ONNX FP32): 26.04 ms/batch (CPU, batch=128)\n",
    "\n",
    "**Provide brief comparison/analysis:**\n",
    "- ONNXRuntime preserved accuracy and provided a large CPU inference speedup versus PyTorch FP32.\n",
    "- ONNX file size is nearly identical to FP32 checkpoint size, as expected for full-precision export.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cab0b",
   "metadata": {},
   "source": [
    "# 2.3 Post Training Quantization (Static)\n",
    "Perform INT8 static quantization. Target: < 5% accuracy drop from FP32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Post Training Quantization (Static)\n",
    "from onnxruntime.quantization import (\n",
    "    CalibrationDataReader,\n",
    "    CalibrationMethod,\n",
    "    QuantFormat,\n",
    "    QuantType,\n",
    "    quantize_static,\n",
    ")\n",
    "\n",
    "CFG_23 = {\n",
    "    'fp32_onnx_path': FP32_ONNX_PATH,\n",
    "    'int8_onnx_path': INT8_STATIC_ONNX_PATH,\n",
    "    'data_root': DATA_ROOT,\n",
    "    'test_batch_size': 128,\n",
    "    'test_num_workers': 0,\n",
    "    'calib_images': 1024,\n",
    "    'calib_batch_size': 128,\n",
    "    'calib_method': 'minmax',  # 'minmax' | 'entropy' | 'percentile'\n",
    "    'warmup_batches': 10,\n",
    "    'benchmark_repeats': 3,\n",
    "    'max_allowed_acc_drop': 5.0,\n",
    "}\n",
    "\n",
    "\n",
    "class CIFAR10CalibrationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, input_name: str, data_root: Path, num_images: int, batch_size: int):\n",
    "        self.input_name = input_name\n",
    "        calib_loader = get_train_loader(\n",
    "            data_root=data_root,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,\n",
    "            seed=42,\n",
    "            augment=False,\n",
    "            subset_size=num_images,\n",
    "        )\n",
    "        self.batches = materialize_numpy_batches(calib_loader)\n",
    "        self._idx = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self._idx >= len(self.batches):\n",
    "            return None\n",
    "        images_np, _ = self.batches[self._idx]\n",
    "        self._idx += 1\n",
    "        return {self.input_name: images_np}\n",
    "\n",
    "    def rewind(self):\n",
    "        self._idx = 0\n",
    "\n",
    "\n",
    "def get_calibration_method(name: str) -> CalibrationMethod:\n",
    "    mapping = {\n",
    "        'minmax': CalibrationMethod.MinMax,\n",
    "        'entropy': CalibrationMethod.Entropy,\n",
    "        'percentile': CalibrationMethod.Percentile,\n",
    "    }\n",
    "    key = name.lower().strip()\n",
    "    if key not in mapping:\n",
    "        raise ValueError(f'Unsupported calib_method: {name}')\n",
    "    return mapping[key]\n",
    "\n",
    "\n",
    "fp32_onnx = ensure_fp32_onnx_exists(\n",
    "    ckpt_path=FP32_CKPT_PATH,\n",
    "    onnx_path=CFG_23['fp32_onnx_path'],\n",
    "    opset=13,\n",
    ")\n",
    "\n",
    "fp32_session = build_ort_session(fp32_onnx)\n",
    "input_name = fp32_session.get_inputs()[0].name\n",
    "\n",
    "calib_reader = CIFAR10CalibrationDataReader(\n",
    "    input_name=input_name,\n",
    "    data_root=CFG_23['data_root'],\n",
    "    num_images=CFG_23['calib_images'],\n",
    "    batch_size=CFG_23['calib_batch_size'],\n",
    ")\n",
    "\n",
    "quantize_static(\n",
    "    model_input=str(fp32_onnx),\n",
    "    model_output=str(CFG_23['int8_onnx_path']),\n",
    "    calibration_data_reader=calib_reader,\n",
    "    quant_format=QuantFormat.QDQ,\n",
    "    activation_type=QuantType.QUInt8,\n",
    "    weight_type=QuantType.QInt8,\n",
    "    per_channel=True,\n",
    "    calibrate_method=get_calibration_method(CFG_23['calib_method']),\n",
    "    extra_options={'ActivationSymmetric': False, 'WeightSymmetric': True},\n",
    ")\n",
    "\n",
    "int8_session = build_ort_session(CFG_23['int8_onnx_path'])\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_root=CFG_23['data_root'],\n",
    "    batch_size=CFG_23['test_batch_size'],\n",
    "    num_workers=CFG_23['test_num_workers'],\n",
    ")\n",
    "test_batches = materialize_numpy_batches(test_loader)\n",
    "\n",
    "fp32_loss, fp32_acc = evaluate_ort_batches(fp32_session, test_batches, desc='FP32 ONNX CPU')\n",
    "int8_loss, int8_acc = evaluate_ort_batches(int8_session, test_batches, desc='INT8 Static ONNX CPU')\n",
    "\n",
    "fp32_perf = benchmark_ort_batches(\n",
    "    fp32_session,\n",
    "    test_batches,\n",
    "    warmup_batches=CFG_23['warmup_batches'],\n",
    "    repeats=CFG_23['benchmark_repeats'],\n",
    ")\n",
    "int8_perf = benchmark_ort_batches(\n",
    "    int8_session,\n",
    "    test_batches,\n",
    "    warmup_batches=CFG_23['warmup_batches'],\n",
    "    repeats=CFG_23['benchmark_repeats'],\n",
    ")\n",
    "\n",
    "fp32_size_kb = Path(fp32_onnx).stat().st_size / 1024\n",
    "int8_size_kb = Path(CFG_23['int8_onnx_path']).stat().st_size / 1024\n",
    "acc_drop = fp32_acc - int8_acc\n",
    "speedup = fp32_perf['ms_per_image'] / int8_perf['ms_per_image']\n",
    "\n",
    "print('\\nStatic PTQ (INT8) Results')\n",
    "print('-' * 72)\n",
    "print(f'FP32 ONNX: {fp32_onnx}')\n",
    "print(f'INT8 ONNX: {CFG_23[\"int8_onnx_path\"]}')\n",
    "print(\n",
    "    f\"Calibration: method={CFG_23['calib_method']}, \"\n",
    "    f\"images={CFG_23['calib_images']}, batch={CFG_23['calib_batch_size']}\"\n",
    ")\n",
    "print(f'FP32 size (KB): {fp32_size_kb:.2f}')\n",
    "print(f'INT8 size (KB): {int8_size_kb:.2f}')\n",
    "print(f'Size reduction: {fp32_size_kb / int8_size_kb:.2f}x')\n",
    "print(f'FP32 test loss/acc: {fp32_loss:.4f} / {fp32_acc:.2f}%')\n",
    "print(f'INT8 test loss/acc: {int8_loss:.4f} / {int8_acc:.2f}%')\n",
    "print(f'Accuracy drop (FP32 - INT8): {acc_drop:.2f}%')\n",
    "print(f\"FP32 latency: {fp32_perf['ms_per_image']:.4f} ms/image ({fp32_perf['images_per_sec']:.2f} img/s)\")\n",
    "print(f\"INT8 latency: {int8_perf['ms_per_image']:.4f} ms/image ({int8_perf['images_per_sec']:.2f} img/s)\")\n",
    "print(f'INT8 speedup vs FP32: {speedup:.2f}x')\n",
    "\n",
    "if acc_drop <= CFG_23['max_allowed_acc_drop']:\n",
    "    print(f\"PASS: Accuracy drop <= {CFG_23['max_allowed_acc_drop']:.2f}%\")\n",
    "else:\n",
    "    print(f\"FAIL: Accuracy drop > {CFG_23['max_allowed_acc_drop']:.2f}%\")\n",
    "    print(\"Tip: increase calib_images or try calib_method='entropy' / 'percentile'.\")\n",
    "\n",
    "STATIC_INT8_TEST_LOSS = float(int8_loss)\n",
    "STATIC_INT8_TEST_ACC = float(int8_acc)\n",
    "STATIC_INT8_ACC_DROP = float(acc_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c16c36",
   "metadata": {},
   "source": [
    "**Fill-in the Results:**\n",
    "- INT8 Model Size: 157.27 KB\n",
    "- INT8 Test Accuracy: 89.15 %\n",
    "- Accuracy Drop: 0.08 %\n",
    "- Inference Time (INT8): 15.94 ms/batch (CPU, batch=128)\n",
    "\n",
    "**Quantization settings used:**\n",
    "- Quantization type: Static PTQ (`quantize_static` in ONNXRuntime)\n",
    "- Quant format: QDQ\n",
    "- Per-channel: Enabled (`per_channel=True`)\n",
    "- Data types: activations `QUInt8`, weights `QInt8`\n",
    "- Calibration: MinMax with 1,024 CIFAR-10 train images, calibration batch size 128\n",
    "- Inference backend: ONNXRuntime `CPUExecutionProvider`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33fd541",
   "metadata": {},
   "source": [
    "# **OPTIONAL - BONUS** 2.4 Post Training Quantization (Dynamic)\n",
    "\n",
    "*(Optional)* Perform INT8 dynamic quantization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Post Training Quantization (Dynamic) - Optional Bonus\n",
    "from onnxruntime.quantization import QuantType, quantize_dynamic\n",
    "\n",
    "CFG_24 = {\n",
    "    'fp32_onnx_path': FP32_ONNX_PATH,\n",
    "    'int8_dynamic_onnx_path': INT8_DYNAMIC_ONNX_PATH,\n",
    "    'data_root': DATA_ROOT,\n",
    "    'test_batch_size': 128,\n",
    "    'test_num_workers': 0,\n",
    "    'op_types_to_quantize': ['MatMul', 'Gemm'],\n",
    "    'weight_type': 'qint8',  # 'qint8' | 'quint8'\n",
    "    'warmup_batches': 10,\n",
    "    'benchmark_repeats': 3,\n",
    "    'max_allowed_acc_drop': 5.0,\n",
    "}\n",
    "\n",
    "\n",
    "def get_dynamic_weight_type(name: str) -> QuantType:\n",
    "    key = name.lower().strip()\n",
    "    if key == 'qint8':\n",
    "        return QuantType.QInt8\n",
    "    if key == 'quint8':\n",
    "        return QuantType.QUInt8\n",
    "    raise ValueError(f'Unsupported dynamic weight type: {name}')\n",
    "\n",
    "\n",
    "fp32_onnx = ensure_fp32_onnx_exists(\n",
    "    ckpt_path=FP32_CKPT_PATH,\n",
    "    onnx_path=CFG_24['fp32_onnx_path'],\n",
    "    opset=13,\n",
    ")\n",
    "\n",
    "quantize_dynamic(\n",
    "    model_input=str(fp32_onnx),\n",
    "    model_output=str(CFG_24['int8_dynamic_onnx_path']),\n",
    "    weight_type=get_dynamic_weight_type(CFG_24['weight_type']),\n",
    "    op_types_to_quantize=CFG_24['op_types_to_quantize'],\n",
    "    per_channel=True,\n",
    "    reduce_range=False,\n",
    "    extra_options={'WeightSymmetric': True},\n",
    ")\n",
    "\n",
    "fp32_session = build_ort_session(fp32_onnx)\n",
    "int8_dyn_session = build_ort_session(CFG_24['int8_dynamic_onnx_path'])\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_root=CFG_24['data_root'],\n",
    "    batch_size=CFG_24['test_batch_size'],\n",
    "    num_workers=CFG_24['test_num_workers'],\n",
    ")\n",
    "test_batches = materialize_numpy_batches(test_loader)\n",
    "\n",
    "fp32_loss, fp32_acc = evaluate_ort_batches(fp32_session, test_batches, desc='FP32 ONNX CPU (for dynamic PTQ)')\n",
    "int8_dyn_loss, int8_dyn_acc = evaluate_ort_batches(int8_dyn_session, test_batches, desc='INT8 Dynamic ONNX CPU')\n",
    "\n",
    "fp32_perf = benchmark_ort_batches(\n",
    "    fp32_session,\n",
    "    test_batches,\n",
    "    warmup_batches=CFG_24['warmup_batches'],\n",
    "    repeats=CFG_24['benchmark_repeats'],\n",
    ")\n",
    "int8_dyn_perf = benchmark_ort_batches(\n",
    "    int8_dyn_session,\n",
    "    test_batches,\n",
    "    warmup_batches=CFG_24['warmup_batches'],\n",
    "    repeats=CFG_24['benchmark_repeats'],\n",
    ")\n",
    "\n",
    "fp32_size_kb = Path(fp32_onnx).stat().st_size / 1024\n",
    "int8_dyn_size_kb = Path(CFG_24['int8_dynamic_onnx_path']).stat().st_size / 1024\n",
    "acc_drop_dyn = fp32_acc - int8_dyn_acc\n",
    "speedup_dyn = fp32_perf['ms_per_image'] / int8_dyn_perf['ms_per_image']\n",
    "\n",
    "print('\\nDynamic PTQ (INT8) Results')\n",
    "print('-' * 72)\n",
    "print(f'FP32 ONNX: {fp32_onnx}')\n",
    "print(f'Dynamic INT8 ONNX: {CFG_24[\"int8_dynamic_onnx_path\"]}')\n",
    "print(f'Dynamic settings: op_types={CFG_24[\"op_types_to_quantize\"]}, weight_type={CFG_24[\"weight_type\"]}, per_channel=True')\n",
    "print(f'FP32 size (KB): {fp32_size_kb:.2f}')\n",
    "print(f'Dynamic INT8 size (KB): {int8_dyn_size_kb:.2f}')\n",
    "print(f'Size reduction: {fp32_size_kb / int8_dyn_size_kb:.2f}x')\n",
    "print(f'FP32 test loss/acc: {fp32_loss:.4f} / {fp32_acc:.2f}%')\n",
    "print(f'Dynamic INT8 test loss/acc: {int8_dyn_loss:.4f} / {int8_dyn_acc:.2f}%')\n",
    "print(f'Accuracy drop (FP32 - INT8): {acc_drop_dyn:.2f}%')\n",
    "print(f'FP32 latency: {fp32_perf[\"ms_per_image\"]:.4f} ms/image ({fp32_perf[\"images_per_sec\"]:.2f} img/s)')\n",
    "print(f'Dynamic INT8 latency: {int8_dyn_perf[\"ms_per_image\"]:.4f} ms/image ({int8_dyn_perf[\"images_per_sec\"]:.2f} img/s)')\n",
    "print(f'Dynamic INT8 speedup vs FP32: {speedup_dyn:.2f}x')\n",
    "\n",
    "if acc_drop_dyn <= CFG_24['max_allowed_acc_drop']:\n",
    "    print(f'PASS: Accuracy drop <= {CFG_24[\"max_allowed_acc_drop\"]:.2f}%')\n",
    "else:\n",
    "    print(f'FAIL: Accuracy drop > {CFG_24[\"max_allowed_acc_drop\"]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14cd0a9",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- INT8 Model Size: 428.77 KB\n",
    "- INT8 Test Accuracy: 89.24 %\n",
    "- Accuracy Drop: -0.01 %\n",
    "- Inference Time (INT8): 28.28 ms/batch (CPU, batch=128)\n",
    "\n",
    "**Comparison with static quantization:**\n",
    "- Dynamic PTQ preserved accuracy but gave minimal compression (~1.01x size reduction) because this CNN is Conv-heavy and dynamic quantization mainly targets MatMul/Gemm.\n",
    "- Static PTQ achieved much better practical gains for this model (157.27 KB and 15.94 ms/batch), so static PTQ is the better deployment option here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1d576",
   "metadata": {},
   "source": [
    "# Summary Table\n",
    "\n",
    "| Metric | FP32 (Original) | FP32 (ONNX) | INT8 Static | INT8 Dynamic (Optional) |\n",
    "|--------|-----------------|-------------|-------------|--------------------------|\n",
    "| Size (KB) | 430.82 | 431.20 | 157.27 | 428.77 |\n",
    "| Accuracy (%) | 89.23 | 89.23 | 89.15 | 89.24 |\n",
    "| Inference (ms/image, CPU) | 1.0480 | 0.2034 | 0.1245 | 0.2209 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f90ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}